{"version":3,"sources":["../../src/services/CrawlerSchedulerService.js"],"names":["runningJobs","Map","generateCrawlerName","index","crawlerContainerPrefix","getCrawlerStateBySettingsUid","storage","settingsUid","Promise","resolve","reject","redisPromises","Array","crawlerCount","map","item","getCurrentCrawlerTask","redis","all","then","results","forEach","value","array","getExecutingCrawlerContainerNameBySettingsUid","crawlerName","uid","taskUid","getCrawlerPromises","tryRemoveCrawlerContainer","token","generateServiceToken","createCrawlerContainer","setCurrentCrawlerTask","startCrawlerContainer","init","crawlerPromises","getCrawlersSettings","mongoDb","crawlers","filter","c","schedule","is_active","crawler","createNewJob","console","log","indexLogItem","elasticSearch","createLogRecord","catch","error","err","toString","destroy","tryRemoveJob","has","Error","job","cronTime","cron_schedule","onTick","enqueueJob","start","set","crawlerUid","get","stop","delete","removeJob","type","message","source_id","enqueueCrawlerMessage"],"mappings":"uRAAA;AACA,mC;AACA,gC;;AAEA,IAAMA,cAAc,IAAIC,GAAJ,EAApB;;AAEA,IAAMC,sBAAsB,SAAtBA,mBAAsB,CAACC,KAAD,eAAc,iBAAOC,sBAArB,GAA8CD,KAA9C,EAA5B;;AAEO,IAAME,sEAA+B,SAA/BA,4BAA+B,CAACC,OAAD,EAAUC,WAAV,UAA0B,IAAIC,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AACnG,YAAMC,gBAAgB,6BAAIC,MAAM,iBAAOC,YAAb,CAAJ,GAAgCC,GAAhC,CAAoC,UAACC,IAAD,EAAOZ,KAAP,EAAiB;AACvE,mBAAO,kBAAWa,qBAAX,CAAiCV,QAAQW,KAAzC,EAAgDf,oBAAoBC,KAApB,CAAhD,CAAP;AACH,SAFqB,CAAtB;AAGAK,gBAAQU,GAAR,CAAYP,aAAZ;AACKQ,YADL,CACU,mBAAW;AACbC,oBAAQC,OAAR,CAAgB,UAACC,KAAD,EAAQnB,KAAR,EAAeoB,KAAf,EAAyB;AACrC,oBAAID,UAAUf,WAAd,EAA2B;AACvBE,4BAAQ,SAAR;AACA;AACH;AACJ,aALD;AAMAA,oBAAQ,MAAR;AACH,SATL;AAUH,KAdqE,CAA1B,EAArC;;AAgBA,IAAMe,wGAAgD,SAAhDA,6CAAgD,CAAClB,OAAD,EAAUC,WAAV,UAA0B,IAAIC,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AACpH,YAAMC,gBAAgB,6BAAIC,MAAM,iBAAOC,YAAb,CAAJ,GAAgCC,GAAhC,CAAoC,UAACC,IAAD,EAAOZ,KAAP,EAAiB;AACvE,gBAAMsB,cAAcvB,oBAAoBC,KAApB,CAApB;AACA,mBAAO,kBAAWa,qBAAX,CAAiCV,QAAQW,KAAzC,EAAgDQ,WAAhD;AACFN,gBADE,CACG,mBAAW;AACb,uBAAO,EAAEM,aAAaA,WAAf,EAA4BC,KAAKC,OAAjC,EAAP;AACH,aAHE,CAAP;AAIH,SANqB,CAAtB;AAOAnB,gBAAQU,GAAR,CAAYP,aAAZ;AACKQ,YADL,CACU,mBAAW;AACbC,oBAAQC,OAAR,CAAgB,UAACC,KAAD,EAAQnB,KAAR,EAAeoB,KAAf,EAAyB;AACrC,oBAAID,MAAMI,GAAN,KAAcnB,WAAlB,EAA+B;AAC3BE,4BAAQa,MAAMG,WAAd;AACA;AACH;AACJ,aALD;AAMAhB,oBAAQ,IAAR;AACH,SATL;AAUH,KAlBsF,CAA1B,EAAtD;;AAoBP,IAAMmB,qBAAqB,SAArBA,kBAAqB,CAACtB,OAAD,EAAa;AACnC,WAAO,6BAAIM,MAAM,iBAAOC,YAAb,CAAJ,GAAgCC,GAAhC,CAAoC,UAACC,IAAD,EAAOZ,KAAP,EAAiB;AACzD,YAAMsB,cAAcvB,oBAAoBC,KAApB,CAApB;;AAEA,eAAO,mBAAY0B,yBAAZ,CAAsCJ,WAAtC;AACFN,YADE,CACG,YAAM;AACR,gBAAMW,QAAQ,mBAAYC,oBAAZ,CAAiCzB,OAAjC,EAA0CmB,WAA1C,CAAd;AACA,mBAAO,mBAAYO,sBAAZ,CAAmCP,WAAnC,EAAgDK,KAAhD,CAAP;AACH,SAJE;AAKFX,YALE,CAKG,oBAAM,kBAAWc,qBAAX,CAAiC3B,QAAQW,KAAzC,EAAgDQ,WAAhD,EAA6D,EAA7D,CAAN,EALH;AAMFN,YANE,CAMG,YAAM;AACR,mBAAO,mBAAYe,qBAAZ,CAAkCT,WAAlC,CAAP;AACH,SARE,CAAP;AASH,KAZO,CAAP;AAaJ,CAdD;;AAgBO,IAAMU,sBAAO,SAAPA,IAAO,CAAC7B,OAAD,UAAa,IAAIE,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AAC9D,YAAI0B,kBAAkBR,mBAAmBtB,OAAnB,CAAtB;;AAEAE,gBAAQU,GAAR,CAAYkB,eAAZ;AACKjB,YADL,CACU,YAAM;AACR,mBAAO,kBAAWkB,mBAAX,CAA+B/B,QAAQgC,OAAvC,CAAP;AACH,SAHL;AAIKnB,YAJL,CAIU,UAACoB,QAAD,EAAc;AAChBA,qBAASC,MAAT,CAAgB,qBAAKC,EAAEC,QAAF,CAAWC,SAAhB,EAAhB,EAA2CtB,OAA3C,CAAmD,UAACuB,OAAD,EAAUzC,KAAV,EAAiBoB,KAAjB,EAA2B;AAC1EsB,6BAAavC,OAAb,EAAsBsC,OAAtB;AACAE,wBAAQC,GAAR,sBAA+BH,QAAQlB,GAAvC;AACH,aAHD;AAIA;AACH,SAVL;AAWKP,YAXL,CAWU,YAAM;AACR2B,oBAAQC,GAAR,CAAY,sCAAZ;AACA,2BAAQC,YAAR;AACI1C,oBAAQ2C,aADZ;AAEIC,4BAAgB,MAAhB,EAAwB,sCAAxB,CAFJ;;AAIAzC,oBAAQ,IAAR;AACH,SAlBL;AAmBK0C,aAnBL,CAmBW,eAAO;AACVL,oBAAQM,KAAR,sDAAiEC,IAAIC,QAAJ,EAAjE;AACA,2BAAQN,YAAR;AACI1C,oBAAQ2C,aADZ;AAEIC,4BAAgB,OAAhB,uDAA4EG,IAAIC,QAAJ,EAA5E,CAFJ;;AAIA5C,mBAAO2C,GAAP;AACH,SA1BL;AA2BH,KA9BgC,CAAb,EAAb;;AAgCA,IAAME,4BAAU,SAAVA,OAAU,CAACjD,OAAD,UAAa,IAAIE,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AACjE,0BAAW2B,mBAAX,CAA+B/B,QAAQgC,OAAvC;AACKnB,YADL,CACU,UAACoB,QAAD,EAAc;AAChBA,qBAASC,MAAT,CAAgB,qBAAKC,EAAEC,QAAF,CAAWC,SAAhB,EAAhB,EAA2CtB,OAA3C,CAAmD,qBAAKmC,aAAaf,EAAEf,GAAf,CAAL,EAAnD;;AAEA,gBAAMU,kBAAkBG;AACnBzB,eADmB,CACf,qBAAK,mBAAYe,yBAAZ,CAAsCY,EAAEf,GAAxC,CAAL,EADe,CAAxB;;AAGA,mBAAOU,eAAP;AACH,SARL;AASKjB,YATL,CASU,UAACiB,eAAD,UAAqB5B,QAAQU,GAAR,CAAYkB,eAAZ,CAArB,EATV;AAUKjB,YAVL,CAUU,YAAM;AACR2B,oBAAQC,GAAR,CAAY,oCAAZ;AACA,2BAAQC,YAAR;AACI1C,oBAAQ2C,aADZ;AAEIC,4BAAgB,MAAhB,EAAwB,oCAAxB,CAFJ;;AAIAzC,oBAAQ,IAAR;AACH,SAjBL;AAkBK0C,aAlBL,CAkBW,eAAO;AACVL,oBAAQM,KAAR,2CAAsDC,IAAIC,QAAJ,EAAtD;AACA,2BAAQN,YAAR;AACI1C,oBAAQ2C,aADZ;AAEIC,4BAAgB,OAAhB,4CAAiEG,IAAIC,QAAJ,EAAjE,CAFJ;;AAIA5C,mBAAO2C,GAAP;AACH,SAzBL;AA0BH,KA3BmC,CAAb,EAAhB;;AA6BA,IAAMR,sCAAe,SAAfA,YAAe,CAACvC,OAAD,EAAUsC,OAAV,EAAsB;;AAE9C,QAAI5C,YAAYyD,GAAZ,CAAgBb,QAAQlB,GAAxB,CAAJ,EAAkC;AAC9B,cAAM,IAAIgC,KAAJ,qBAA2Bd,QAAQlB,GAAnC,iCAAN;AACH;;AAED,QAAMiC,MAAM,kBAAY;AACpBC,kBAAUhB,QAAQF,QAAR,CAAiBmB,aADP;AAEpBC,gBAAQ,0BAAMC,WAAWzD,OAAX,EAAoBsC,QAAQlB,GAA5B,CAAN,EAFY;AAGpBsC,eAAO,IAHa,EAAZ,CAAZ;;;AAMAhE,gBAAYiE,GAAZ,CAAgBrB,QAAQlB,GAAxB,EAA6BiC,GAA7B;AACH,CAbM;;AAeA,IAAMH,sCAAe,SAAfA,YAAe,CAACU,UAAD,EAAgB;AACxC,QAAI,CAAClE,YAAYyD,GAAZ,CAAgBS,UAAhB,CAAL,EAAkC;AAC9B;AACH;;AAED,QAAMP,MAAM3D,YAAYmE,GAAZ,CAAgBD,UAAhB,CAAZ;AACAP,QAAIS,IAAJ;AACApE,gBAAYqE,MAAZ,CAAmBH,UAAnB;AACH,CARM;;AAUA,IAAMI,gCAAY,SAAZA,SAAY,CAACJ,UAAD,EAAgB;AACrC,QAAI,CAAClE,YAAYyD,GAAZ,CAAgBS,UAAhB,CAAL,EAAkC;AAC9B,cAAM,IAAIR,KAAJ,wBAA8BQ,UAA9B,iCAAN;AACH;;AAEDV,iBAAaU,UAAb;AACH,CANM;;AAQP,IAAMhB,kBAAkB,SAAlBA,eAAkB,CAACqB,IAAD,EAAOC,OAAP,UAAoB;AACxCD,cAAMA,IADkC;AAExCE,mBAAW,QAF6B;AAGxCD,iBAASA,OAH+B,EAApB,EAAxB;;;AAMA,IAAMT,aAAa,SAAbA,UAAa,CAACzD,OAAD,EAAU4D,UAAV,EAAyB;AACxC,sBAAWQ,qBAAX,CAAiCpE,OAAjC,EAA0C,EAAEoB,KAAKwC,UAAP,EAA1C;AACK/C,QADL,CACU,YAAM;AACR2B,gBAAQC,GAAR,YAAoBmB,UAApB;AACA,uBAAQlB,YAAR;AACI1C,gBAAQ2C,aADZ;AAEIC,wBAAgB,MAAhB,aAAgCgB,UAAhC,iBAFJ;AAGH,KANL;AAOKf,SAPL,CAOW,eAAO;AACVL,gBAAQM,KAAR,8BAAwCc,UAAxC,mBAA+Db,IAAIC,QAAJ,EAA/D;AACA,uBAAQN,YAAR;AACI1C,gBAAQ2C,aADZ;AAEIC,wBAAgB,OAAhB,+BAAmDgB,UAAnD,mBAA0Eb,IAAIC,QAAJ,EAA1E,CAFJ;AAGH,KAZL;;AAcH,CAfD","file":"CrawlerSchedulerService.js","sourcesContent":["import { CronJob } from 'cron'\nimport config from '../config'\nimport { CacheProxy, DockerProxy, MongoProxy, EsProxy, AuthService, QueueProxy } from './index'\n\nconst runningJobs = new Map()\n\nconst generateCrawlerName = (index) => `${config.crawlerContainerPrefix}${index}`\n\nexport const getCrawlerStateBySettingsUid = (storage, settingsUid) => new Promise((resolve, reject) => {\n    const redisPromises = [...Array(config.crawlerCount)].map((item, index) => {\n        return CacheProxy.getCurrentCrawlerTask(storage.redis, generateCrawlerName(index))\n    })\n    Promise.all(redisPromises)\n        .then(results => {\n            results.forEach((value, index, array) => {\n                if (value === settingsUid) {\n                    resolve('running')\n                    return\n                }\n            })\n            resolve('idle')\n        })\n})\n\nexport const getExecutingCrawlerContainerNameBySettingsUid = (storage, settingsUid) => new Promise((resolve, reject) => {\n    const redisPromises = [...Array(config.crawlerCount)].map((item, index) => {\n        const crawlerName = generateCrawlerName(index)\n        return CacheProxy.getCurrentCrawlerTask(storage.redis, crawlerName)\n            .then(taskUid => {\n                return { crawlerName: crawlerName, uid: taskUid }\n            })\n    })\n    Promise.all(redisPromises)\n        .then(results => {\n            results.forEach((value, index, array) => {\n                if (value.uid === settingsUid) {\n                    resolve(value.crawlerName)\n                    return\n                }\n            })\n            resolve(null)\n        })\n})\n\nconst getCrawlerPromises = (storage) => {\n     return [...Array(config.crawlerCount)].map((item, index) => {\n        const crawlerName = generateCrawlerName(index)\n\n        return DockerProxy.tryRemoveCrawlerContainer(crawlerName)\n            .then(() => {\n                const token = AuthService.generateServiceToken(storage, crawlerName)\n                return DockerProxy.createCrawlerContainer(crawlerName, token)\n            })\n            .then(() => CacheProxy.setCurrentCrawlerTask(storage.redis, crawlerName, ''))\n            .then(() => {\n                return DockerProxy.startCrawlerContainer(crawlerName)\n            })\n    })\n}\n\nexport const init = (storage) => new Promise((resolve, reject) => {\n    let crawlerPromises = getCrawlerPromises(storage)    \n\n    Promise.all(crawlerPromises)\n        .then(() => {\n            return MongoProxy.getCrawlersSettings(storage.mongoDb)\n        })\n        .then((crawlers) => {\n            crawlers.filter(c => c.schedule.is_active).forEach((crawler, index, array) => {\n                createNewJob(storage, crawler)\n                console.log(`Job for crawler ${crawler.uid} created`)\n            })\n            return\n        })\n        .then(() => {\n            console.log('Crawler schedule service initialized')\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('info', 'Crawler schedule service initialized')\n            )\n            resolve(true)\n        })\n        .catch(err => {\n            console.error(`Failed to initialize crawler scheduler service. ${err.toString()}`)\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('error', `Failed to initialize crawler scheduler service. ${err.toString()}`)\n            )\n            reject(err)\n        })\n})\n\nexport const destroy = (storage) => new Promise((resolve, reject) => {\n    MongoProxy.getCrawlersSettings(storage.mongoDb)\n        .then((crawlers) => {\n            crawlers.filter(c => c.schedule.is_active).forEach(c => tryRemoveJob(c.uid))\n\n            const crawlerPromises = crawlers\n                .map(c => DockerProxy.tryRemoveCrawlerContainer(c.uid))\n\n            return crawlerPromises\n        })\n        .then((crawlerPromises) => Promise.all(crawlerPromises))\n        .then(() => {\n            console.log('Crawler schedule service destroyed')\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('info', 'Crawler schedule service destroyed')\n            )\n            resolve(true)\n        })\n        .catch(err => {\n            console.error(`Failed to destroy scheduler service. ${err.toString()}`)\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('error', `Failed to destroy scheduler service. ${err.toString()}`)\n            )\n            reject(err)\n        })\n})\n\nexport const createNewJob = (storage, crawler) => {\n\n    if (runningJobs.has(crawler.uid)) {\n        throw new Error(`Can't add job ${crawler.uid}, because it already exists`)\n    }\n\n    const job = new CronJob({\n        cronTime: crawler.schedule.cron_schedule,\n        onTick: () => enqueueJob(storage, crawler.uid),\n        start: true\n    })\n\n    runningJobs.set(crawler.uid, job)\n}\n\nexport const tryRemoveJob = (crawlerUid) => {\n    if (!runningJobs.has(crawlerUid)) {\n        return\n    }\n\n    const job = runningJobs.get(crawlerUid)\n    job.stop()\n    runningJobs.delete(crawlerUid)\n}\n\nexport const removeJob = (crawlerUid) => {\n    if (!runningJobs.has(crawlerUid)) {\n        throw new Error(`Can't remove job ${crawlerUid}, because it doesn't exist`)\n    }\n\n    tryRemoveJob(crawlerUid)\n}\n\nconst createLogRecord = (type, message) => ({\n    type: type,\n    source_id: 'webapi',\n    message: message\n})\n\nconst enqueueJob = (storage, crawlerUid) => {\n    QueueProxy.enqueueCrawlerMessage(storage, { uid: crawlerUid })\n        .then(() => {\n            console.log(`Job '${crawlerUid}' enqueued`)\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('info', `Job '${crawlerUid}' enqueued`))\n        })\n        .catch(err => {\n            console.error(`Failed to enqueue job '${crawlerUid}'. Error: ${err.toString()}`)\n            EsProxy.indexLogItem(\n                storage.elasticSearch,\n                createLogRecord('error', `Failed to enqueue job '${crawlerUid}'. Error: ${err.toString()}`))\n        })\n\n}"]}